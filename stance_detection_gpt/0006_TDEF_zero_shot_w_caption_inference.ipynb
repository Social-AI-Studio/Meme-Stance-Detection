{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "VmGPPrIgUuOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz9w0iKbUgFU"
      },
      "outputs": [],
      "source": [
        "!pip install openai cohere tiktoken typing-extensions==4.5.0\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "import inspect\n",
        "import os\n",
        "import base64\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "from tenacity import (\n",
        "    retry,\n",
        "    stop_after_attempt,\n",
        "    wait_random_exponential,\n",
        ")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount drive"
      ],
      "metadata": {
        "id": "c2G0hrkUh8H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qd5KX06ljILs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authentication"
      ],
      "metadata": {
        "id": "89Hw0z3qa_Ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")"
      ],
      "metadata": {
        "id": "-ygIIut5Wjho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset"
      ],
      "metadata": {
        "id": "iwPyumV3gkgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_defense_memes_test_w_captions = pd.read_csv('/content/drive/MyDrive/stance_detection_datasets_GPT/total_defense_memes/total_defense_memes_test_caption.csv')"
      ],
      "metadata": {
        "id": "hq5BAOh9gl1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function to add definitions"
      ],
      "metadata": {
        "id": "SfqPWatJLpmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def definition(x):\n",
        "    if x == 'Military Defence':\n",
        "        return \"\"\"Singapore's Military Defence: Strong and formidable defence force made up of Regulars and National Servicemen, and supported by the entire Singapore.\"\"\"\n",
        "    elif x == 'Civil Defence':\n",
        "        return \"\"\"Singapore's Civil Defence: Collective effort of the Singaporean society to spot signs of threats, respond effectively and recover quickly from crisis.\"\"\"\n",
        "    elif x == 'Economic Defence':\n",
        "        return \"\"\"Singapore's Economic Defence: Strong and resilient Singaporean economy that is globally competitive and able to bounce back from any crisis.\"\"\"\n",
        "    elif x == 'Social Defence':\n",
        "        return \"\"\"Singapore's Social Defence: Bonds that unite Singaporeans, built on trust and understanding among people of different races and religions, living in harmony and looking out for one another.\"\"\"\n",
        "    elif x == 'Psychological Defence':\n",
        "        return \"\"\"Singapore's Psychological Defence: The will and resolve to defend the Singaporean way of life and interests, the fighting spirit to overcome challenges together.\"\"\"\n",
        "    elif x == 'Digital Defence':\n",
        "        return \"\"\"Singapore's Digital Defence: Being secure, alert and responsible online.\"\"\""
      ],
      "metadata": {
        "id": "Q0oSuzodLp7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_defense_memes_test_w_captions['pillar_w_definition'] = total_defense_memes_test_w_captions['pillar'].apply(lambda x: definition(x))"
      ],
      "metadata": {
        "id": "9mal87ndLs_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function to clean responses"
      ],
      "metadata": {
        "id": "E-KfN8IhPgkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remap(x):\n",
        "    x = x.lower()\n",
        "    if x == 'bad':\n",
        "        return 'Against'\n",
        "    elif x == 'neutral':\n",
        "        return 'Neutral'\n",
        "    elif  x == 'good':\n",
        "        return 'Supportive'\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "ak52TBE4PguA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set prompts"
      ],
      "metadata": {
        "id": "RcDrKCASgmKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_with_caption(pillar, pillar_w_definition, caption):\n",
        "    return inspect.cleandoc(f\"\"\"\n",
        "    Description of this meme: \\\"\\\"\\\"\n",
        "    {caption}\n",
        "    \\\"\\\"\\\"\n",
        "    {pillar_w_definition}\n",
        "    Indicate whether this meme is bad, neutral or good towards Singapore's {pillar}.\n",
        "    Constraint: Without using any other words, answer either bad, neutral, good.\"\"\")"
      ],
      "metadata": {
        "id": "Po-nnNpFL9dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a function to generate text using the `gpt-4-vision-preview` model"
      ],
      "metadata": {
        "id": "vsOT8_FtbJTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode the image. via\n",
        "# https://platform.openai.com/docs/guides/vision\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')"
      ],
      "metadata": {
        "id": "s6GLvMxZJQ7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prevent rate limit errors. via\n",
        "# https://github.com/openai/openai-cookbook/blob/main/examples/\n",
        "# How_to_handle_rate_limits.ipynb\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
        "# Call the OPENAI API. via\n",
        "# https://platform.openai.com/docs/guides/vision\n",
        "def prediction(image, pillar, pillar_w_definition, caption):\n",
        "    completion = client.chat.completions.create(\n",
        "    model=\"gpt-4-vision-preview\",\n",
        "    messages=[\n",
        "        {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"text\", \"text\": prompt_with_caption(pillar, pillar_w_definition, caption)},\n",
        "            {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "                \"url\": f\"data:image/jpeg;base64,{encode_image(image)}\",\n",
        "            },\n",
        "            },\n",
        "        ],\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=4096,\n",
        "    temperature=0,\n",
        "    seed=1,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content, completion.usage.prompt_tokens, completion.usage.completion_tokens"
      ],
      "metadata": {
        "id": "Z6fwDTZ7bJqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Call the `prediction` function and save inferences"
      ],
      "metadata": {
        "id": "jgoU7PPux5Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df_temp = total_defense_memes_test_w_captions.copy(deep=True)\n",
        "# Create new columns by applying function. via\n",
        "# https://stackoverflow.com/a/52363890\n",
        "df_temp[['prediction', 'prompt_tokens_prediction', 'completion_tokens_prediction']] = df_temp.apply(lambda row: prediction(row.image, row.pillar, row.pillar_w_definition, row.caption), axis='columns', result_type='expand')\n",
        "df_temp.to_csv('/content/drive/MyDrive/stance_detection_datasets_GPT/total_defense_memes/total_defense_memes_test_zero_shot_w_caption_inference.csv', index=False)"
      ],
      "metadata": {
        "id": "uXIzyiegG5sz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7093c7b7-dfff-46a5-8688-02f8e0e827d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 20.3 s, sys: 2.21 s, total: 22.5 s\n",
            "Wall time: 43min 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp['prediction'] = df_temp['prediction'].apply(lambda x: remap(x))\n",
        "print(df_temp['prediction'].value_counts())\n",
        "print(df_temp['prediction'].isna().sum())\n",
        "df_temp['prediction'] = df_temp['prediction'].apply(lambda x: x if x is not None else np.random.choice(['Against', 'Neutral', 'Supportive']))\n",
        "print(f1_score(df_temp['stance'].values, df_temp['prediction'].values, labels=['Against', 'Neutral', 'Supportive'], average='macro'))\n",
        "print(classification_report(df_temp['stance'].values, df_temp['prediction'].values, labels=['Against', 'Neutral', 'Supportive']))"
      ],
      "metadata": {
        "id": "T87R9cWdPpf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39dea188-8c01-45eb-ffa3-19dc9081d881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neutral       571\n",
            "Against       149\n",
            "Supportive     49\n",
            "Name: prediction, dtype: int64\n",
            "2\n",
            "0.614629630013695\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Against       0.91      0.39      0.54       352\n",
            "     Neutral       0.55      0.95      0.70       332\n",
            "  Supportive       0.84      0.47      0.60        87\n",
            "\n",
            "    accuracy                           0.64       771\n",
            "   macro avg       0.77      0.60      0.61       771\n",
            "weighted avg       0.75      0.64      0.62       771\n",
            "\n"
          ]
        }
      ]
    }
  ]
}